{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joey674/DA3/blob/main/notebooks/semantic_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b470389d-a897-416e-9601-aeacb39cd694",
      "metadata": {
        "id": "b470389d-a897-416e-9601-aeacb39cd694"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb5c8577-7dff-41b1-9b04-2dca12940e02",
      "metadata": {
        "id": "eb5c8577-7dff-41b1-9b04-2dca12940e02"
      },
      "source": [
        "# Semantic Segmentation <a target=\"_blank\" href=\"https://colab.research.google.com/github/facebookresearch/dinov2/blob/main/notebooks/semantic_segmentation.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "febdf412-5ad0-4bbc-9530-754f92dcc491",
      "metadata": {
        "id": "febdf412-5ad0-4bbc-9530-754f92dcc491"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "INSTALL = False # Switch this to install dependencies\n",
        "if INSTALL: # Try installing package with extras\n",
        "    REPO_URL = \"https://github.com/facebookresearch/dinov2\"\n",
        "    !{sys.executable} -m pip install -e {REPO_URL}'[extras]' --extra-index-url https://download.pytorch.org/whl/cu117  --extra-index-url https://pypi.nvidia.com\n",
        "    pip install -U openmim\n",
        "    mim install mmengine\n",
        "    mim install \"mmcv>=2.0.0\"\n",
        "    mim install \"mmseg>=1.0.0\"\n",
        "else:\n",
        "    REPO_PATH = \"<FIXME>\" # Specify a local path to the repository (or use installed package instead)\n",
        "    sys.path.append(REPO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efdf378b-0591-4879-9db6-6a4ab582d49f",
      "metadata": {
        "id": "efdf378b-0591-4879-9db6-6a4ab582d49f"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "90223c04-e7da-4738-bb16-d4f7025aa3eb",
      "metadata": {
        "id": "90223c04-e7da-4738-bb16-d4f7025aa3eb",
        "outputId": "0c61793c-f5a7-449f-ee99-5c1687d134a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mmseg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-176059793.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_segmentor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_segmentor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdinov2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mmseg'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import math\n",
        "import itertools\n",
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from mmseg.apis import init_segmentor, inference_segmentor\n",
        "\n",
        "import dinov2.eval.segmentation.models\n",
        "\n",
        "\n",
        "class CenterPadding(torch.nn.Module):\n",
        "    def __init__(self, multiple):\n",
        "        super().__init__()\n",
        "        self.multiple = multiple\n",
        "\n",
        "    def _get_pad(self, size):\n",
        "        new_size = math.ceil(size / self.multiple) * self.multiple\n",
        "        pad_size = new_size - size\n",
        "        pad_size_left = pad_size // 2\n",
        "        pad_size_right = pad_size - pad_size_left\n",
        "        return pad_size_left, pad_size_right\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def forward(self, x):\n",
        "        pads = list(itertools.chain.from_iterable(self._get_pad(m) for m in x.shape[:1:-1]))\n",
        "        output = F.pad(x, pads)\n",
        "        return output\n",
        "\n",
        "\n",
        "def create_segmenter(cfg, backbone_model):\n",
        "    model = init_segmentor(cfg)\n",
        "    model.backbone.forward = partial(\n",
        "        backbone_model.get_intermediate_layers,\n",
        "        n=cfg.model.backbone.out_indices,\n",
        "        reshape=True,\n",
        "    )\n",
        "    if hasattr(backbone_model, \"patch_size\"):\n",
        "        model.backbone.register_forward_pre_hook(lambda _, x: CenterPadding(backbone_model.patch_size)(x[0]))\n",
        "    model.init_weights()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5724efc-b2b8-46ed-94e1-7fee59a39ed9",
      "metadata": {
        "id": "a5724efc-b2b8-46ed-94e1-7fee59a39ed9"
      },
      "source": [
        "## Load pretrained backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d51b932-1157-45ce-997f-572ad417a12f",
      "metadata": {
        "id": "2d51b932-1157-45ce-997f-572ad417a12f"
      },
      "outputs": [],
      "source": [
        "BACKBONE_SIZE = \"small\" # in (\"small\", \"base\", \"large\" or \"giant\")\n",
        "\n",
        "\n",
        "backbone_archs = {\n",
        "    \"small\": \"vits14\",\n",
        "    \"base\": \"vitb14\",\n",
        "    \"large\": \"vitl14\",\n",
        "    \"giant\": \"vitg14\",\n",
        "}\n",
        "backbone_arch = backbone_archs[BACKBONE_SIZE]\n",
        "backbone_name = f\"dinov2_{backbone_arch}\"\n",
        "\n",
        "backbone_model = torch.hub.load(repo_or_dir=\"facebookresearch/dinov2\", model=backbone_name)\n",
        "backbone_model.eval()\n",
        "backbone_model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c90501-d6ef-436e-b1a1-72e63b0534e3",
      "metadata": {
        "id": "c1c90501-d6ef-436e-b1a1-72e63b0534e3"
      },
      "source": [
        "## Load pretrained segmentation head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0bf0b7f-ad98-4cfb-8120-f076df8f8933",
      "metadata": {
        "id": "d0bf0b7f-ad98-4cfb-8120-f076df8f8933"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "\n",
        "import mmcv\n",
        "from mmcv.runner import load_checkpoint\n",
        "\n",
        "\n",
        "def load_config_from_url(url: str) -> str:\n",
        "    with urllib.request.urlopen(url) as f:\n",
        "        return f.read().decode()\n",
        "\n",
        "\n",
        "HEAD_SCALE_COUNT = 3 # more scales: slower but better results, in (1,2,3,4,5)\n",
        "HEAD_DATASET = \"voc2012\" # in (\"ade20k\", \"voc2012\")\n",
        "HEAD_TYPE = \"ms\" # in (\"ms, \"linear\")\n",
        "\n",
        "\n",
        "DINOV2_BASE_URL = \"https://dl.fbaipublicfiles.com/dinov2\"\n",
        "head_config_url = f\"{DINOV2_BASE_URL}/{backbone_name}/{backbone_name}_{HEAD_DATASET}_{HEAD_TYPE}_config.py\"\n",
        "head_checkpoint_url = f\"{DINOV2_BASE_URL}/{backbone_name}/{backbone_name}_{HEAD_DATASET}_{HEAD_TYPE}_head.pth\"\n",
        "\n",
        "cfg_str = load_config_from_url(head_config_url)\n",
        "cfg = mmcv.Config.fromstring(cfg_str, file_format=\".py\")\n",
        "if HEAD_TYPE == \"ms\":\n",
        "    cfg.data.test.pipeline[1][\"img_ratios\"] = cfg.data.test.pipeline[1][\"img_ratios\"][:HEAD_SCALE_COUNT]\n",
        "    print(\"scales:\", cfg.data.test.pipeline[1][\"img_ratios\"])\n",
        "\n",
        "model = create_segmenter(cfg, backbone_model=backbone_model)\n",
        "load_checkpoint(model, head_checkpoint_url, map_location=\"cpu\")\n",
        "model.cuda()\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dc1b106-d28c-41cc-9ddd-f558d66a4715",
      "metadata": {
        "id": "2dc1b106-d28c-41cc-9ddd-f558d66a4715"
      },
      "source": [
        "## Load sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44511634-8243-4662-a512-4531014adb32",
      "metadata": {
        "id": "44511634-8243-4662-a512-4531014adb32"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def load_image_from_url(url: str) -> Image:\n",
        "    with urllib.request.urlopen(url) as f:\n",
        "        return Image.open(f).convert(\"RGB\")\n",
        "\n",
        "\n",
        "EXAMPLE_IMAGE_URL = \"https://dl.fbaipublicfiles.com/dinov2/images/example.jpg\"\n",
        "\n",
        "\n",
        "image = load_image_from_url(EXAMPLE_IMAGE_URL)\n",
        "display(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3240cb-54d0-438d-99e8-8c1af534f830",
      "metadata": {
        "id": "7e3240cb-54d0-438d-99e8-8c1af534f830"
      },
      "source": [
        "## Semantic segmentation on sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49226d5b-83fc-4cfb-ba06-407bb2c0d96f",
      "metadata": {
        "id": "49226d5b-83fc-4cfb-ba06-407bb2c0d96f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import dinov2.eval.segmentation.utils.colormaps as colormaps\n",
        "\n",
        "\n",
        "DATASET_COLORMAPS = {\n",
        "    \"ade20k\": colormaps.ADE20K_COLORMAP,\n",
        "    \"voc2012\": colormaps.VOC2012_COLORMAP,\n",
        "}\n",
        "\n",
        "\n",
        "def render_segmentation(segmentation_logits, dataset):\n",
        "    colormap = DATASET_COLORMAPS[dataset]\n",
        "    colormap_array = np.array(colormap, dtype=np.uint8)\n",
        "    segmentation_values = colormap_array[segmentation_logits + 1]\n",
        "    return Image.fromarray(segmentation_values)\n",
        "\n",
        "\n",
        "array = np.array(image)[:, :, ::-1] # BGR\n",
        "segmentation_logits = inference_segmentor(model, array)[0]\n",
        "segmented_image = render_segmentation(segmentation_logits, HEAD_DATASET)\n",
        "display(segmented_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de40012e-a01e-4e73-bb71-3048f16d41c8",
      "metadata": {
        "id": "de40012e-a01e-4e73-bb71-3048f16d41c8"
      },
      "source": [
        "## Load pretrained segmentation model (Mask2Former)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff2cbbbe-c53c-4e5b-977f-c2a7d93f4b8c",
      "metadata": {
        "id": "ff2cbbbe-c53c-4e5b-977f-c2a7d93f4b8c"
      },
      "outputs": [],
      "source": [
        "import dinov2.eval.segmentation_m2f.models.segmentors\n",
        "\n",
        "CONFIG_URL = f\"{DINOV2_BASE_URL}/dinov2_vitg14/dinov2_vitg14_ade20k_m2f_config.py\"\n",
        "CHECKPOINT_URL = f\"{DINOV2_BASE_URL}/dinov2_vitg14/dinov2_vitg14_ade20k_m2f.pth\"\n",
        "\n",
        "cfg_str = load_config_from_url(CONFIG_URL)\n",
        "cfg = mmcv.Config.fromstring(cfg_str, file_format=\".py\")\n",
        "\n",
        "model = init_segmentor(cfg)\n",
        "load_checkpoint(model, CHECKPOINT_URL, map_location=\"cpu\")\n",
        "model.cuda()\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53c0309f-df2b-4912-bca5-e57d8b3875b3",
      "metadata": {
        "id": "53c0309f-df2b-4912-bca5-e57d8b3875b3"
      },
      "source": [
        "## Semantic segmentation on sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4abb13b-0e5a-4a40-8d44-21da4286ba7d",
      "metadata": {
        "id": "f4abb13b-0e5a-4a40-8d44-21da4286ba7d"
      },
      "outputs": [],
      "source": [
        "array = np.array(image)[:, :, ::-1] # BGR\n",
        "segmentation_logits = inference_segmentor(model, array)[0]\n",
        "segmented_image = render_segmentation(segmentation_logits, \"ade20k\")\n",
        "display(segmented_image)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}